/**
* Hub Miner: a hubness-aware machine learning experimentation library.
* Copyright (C) 2014  Nenad Tomasev. Email: nenad.tomasev at gmail.com
* 
* This program is free software: you can redistribute it and/or modify it under
* the terms of the GNU General Public License as published by the Free Software
* Foundation, either version 3 of the License, or (at your option) any later
* version.
* 
* This program is distributed in the hope that it will be useful, but WITHOUT
* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
* FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License along with
* this program. If not, see <http://www.gnu.org/licenses/>.
*/
package images.mining.codebook;

import data.representation.DataInstance;
import data.representation.DataSet;
import data.representation.images.quantized.QuantizedImageHistogram;
import distances.primary.CombinedMetric;
import ioformat.IOARFF;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStreamReader;
import java.util.HashMap;
import util.CommandLineParser;
import util.fileFilters.DescFileNameFilter;
import util.fileFilters.DirectoryFilter;

/**
 * This class generates a quantized dataset representation from the specified
 * codebook and the specified descriptor files, while ignoring files specified
 * in a separate tabu file.
 *
 * @author Nenad Tomasev <nenad.tomasev at gmail.com>
 */
public class GenericHistogramUtil {

    private File target = null;
    private boolean recursive = true;
    private DataSet quantizedData;
    private CombinedMetric cmet = CombinedMetric.FLOAT_EUCLIDEAN;
    private HashMap<String, String> tabuPathMap;
    GenericCodeBook codebook;
    int descLength;

    /**
     * @param cmet CombinedMetric object for distance calculations.
     */
    public void setCombinedMetirc(CombinedMetric cmet) {
        this.cmet = cmet;
    }

    /**
     * @return CombinedMetric object for distance calculations.
     */
    public CombinedMetric getCombinedMetric() {
        return cmet;
    }

    /**
     * The main method for quantizing a representation.
     *
     * @param args Command line parameters, as specified.
     * @throws Exception
     */
    public static void main(String[] args) throws Exception {
        CommandLineParser clp = new CommandLineParser(true);
        clp.addParam("-featureInput", "Path to the input file containing the "
                + "descriptors or a directory containing files with descriptors"
                + "in files with a 'desc' extension generated by OpenCV.",
                CommandLineParser.STRING, true, false);
        clp.addParam("-inCodebookFile", "Path to where the codebook is "
                + "defined.", CommandLineParser.STRING,
                true, false);
        clp.addParam("-outHistogramFile", "Where to persist the generated"
                + "histograms.", CommandLineParser.STRING,
                true, false);
        clp.addParam("-descLength", "Integer that is the descriptor length.",
                CommandLineParser.INTEGER, true, false);
        clp.addParam("-tabu", "File with a newline separated list of files that"
                + "are to be ignored", CommandLineParser.STRING, false, false);
        clp.parseLine(args);
        File inFile = new File((String) clp.getParamValues("-featureInput").
                get(0));
        File outFile = new File((String) clp.getParamValues(
                "-outHistogramFile").get(0));
        int descLength = (Integer) clp.getParamValues("-descLength").get(0);
        GenericHistogramUtil ghu = new GenericHistogramUtil(inFile, true,
                descLength);
        ghu.tabuPathMap = new HashMap<>(500);
        if (clp.hasParamValue("-tabu")) {
            ghu.populateTabuMap((String) clp.getParamValues("-tabu").get(0));
        }
        ghu.loadCodebookFromFile((String) clp.getParamValues("-inCodebookFile").
                get(0));
        ghu.calculateQuantizedRepresentation();
        IOARFF persister = new IOARFF();
        persister.save(ghu.quantizedData, outFile.getPath(), null);
    }

    /**
     * Loads the codebook from a file and initializes the DataSet.
     *
     * @param filePath Input file path to the codebook file.
     */
    public void loadCodebookFromFile(String filePath) throws Exception {
        codebook = new GenericCodeBook();
        codebook.loadCodeBookFromFile(new File(filePath));
        int numCodebooks = codebook.getSize();
        quantizedData.iAttrNames = new String[numCodebooks];
        for (int i = 0; i < numCodebooks; i++) {
            quantizedData.iAttrNames[i] = "CodebookAtt" + i;
        }
        quantizedData.sAttrNames = new String[1];
        quantizedData.sAttrNames[0] = "Path";
    }

    /**
     * Populates a map of tabued file paths, image representations to ignore.
     *
     * @param inFilePath
     */
    public void populateTabuMap(String inFilePath) throws Exception {
        BufferedReader br = new BufferedReader(new InputStreamReader(
                new FileInputStream(new File(inFilePath))));
        try {
            String s = br.readLine();
            while (s != null) {
                tabuPathMap.put(s, s);
                s = br.readLine();
            }
        } catch (Exception e) {
            System.err.println(e.getMessage());
        } finally {
            br.close();
        }
    }

    public GenericHistogramUtil(File target, boolean recursive, int descLen) {
        // If the target is a directory, clustering will be done for all arff
        // files in the directory. If it is a file, only for the given file.
        this.target = target;
        this.recursive = recursive;
        this.descLength = descLen;
        quantizedData = new DataSet();
    }

    /**
     * Loads the descriptors from a file.
     *
     * @param inFile Input file in feature descriptor format from OpenCV, which
     * is essentially plain csv.
     * @param perc Float value that is the percentage of features to take.
     */
    private DataSet loadFeaturesFromDescriptorFile(File inFile)
            throws Exception {
        DataSet featureRepresentation = new DataSet();
        featureRepresentation.fAttrNames = new String[descLength];
        for (int i = 0; i < descLength; i++) {
            featureRepresentation.fAttrNames[i] = "LocalAtt" + i;
        }
        BufferedReader br = new BufferedReader(new InputStreamReader(
                new FileInputStream(inFile)));
        try {
            String s = br.readLine();
            while (s != null) {
                DataInstance instance = new DataInstance(featureRepresentation);
                // Parse a single line as a feature.
                String[] items = s.split(",");
                for (int i = 0; i < items.length; i++) {
                    instance.fAttr[i] = Float.parseFloat(items[i]);
                }
                featureRepresentation.addDataInstance(instance);
                instance.embedInDataset(featureRepresentation);
                s = br.readLine();
            }
        } catch (Exception e) {
            System.err.println(e.getMessage());
        } finally {
            br.close();
        }
        return featureRepresentation;
    }

    /**
     * Loads the descriptor data from a directory.
     *
     * @param inDir Input directory.
     */
    private void processDirectory(File inDir)
            throws Exception {
        File[] descFiles = inDir.listFiles(new DescFileNameFilter());
        File[] subdirectories = inDir.listFiles(new DirectoryFilter());
        if (recursive) {
            for (File dir : subdirectories) {
                processDirectory(dir);
            }
        }
        for (File descFile : descFiles) {
            if (!tabuPathMap.containsKey(descFile.getAbsolutePath())) {
                DataSet imageRep = loadFeaturesFromDescriptorFile(descFile);
                QuantizedImageHistogram qih = codebook.
                        getHistogramForImageRepresentation(imageRep,
                        descFile.getPath());
                qih.sAttr = new String[1];
                qih.sAttr[0] = descFile.getPath();
                quantizedData.addDataInstance(qih);
                qih.embedInDataset(quantizedData);
            }
        }
    }

    /**
     * Calculates the quantized feature representation by loading the descriptor
     * files for all images and compiling a final representation.
     */
    public void calculateQuantizedRepresentation() throws Exception {
        if (target.isDirectory()) {
            processDirectory(target);
        }
    }
}
